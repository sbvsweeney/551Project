---
title: "STATS 551 Project Report"
author: 'Team 26: Suzy McTaggart, Avery Winn, Melody Wu'
date: "Due April 19 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(rstanarm)
library(bayestestR)
library(bayesplot)
library(insight)
```

## Research Questions

The overarching research question is—What do these popular songs have in common and why do people like these songs? We can narrow down to the following sub-questions:

1) How do songs’ characteristics correlate with their popularity (with year as a potential random effect)?
2) What are some of the most prevalent characteristics of the top 10 most popular songs in each year? In other words, what are some characteristics that can help predict whether a song will be a hit?
3) What are the typical duration and beats per minute of the popular songs and how do these patterns change over time?


#### Data

```{r data}
#The data was collected by Leonardo Henrique through the website “Organize Your Music” (Link). The documentation on the variables and how they are defined can be found on the Organize Your Music site. The list of 603 songs in the data set are the top songs of the years from 2010 to 2019, according to Billboard.

read_csv("https://raw.githubusercontent.com/sbvsweeney/551Project/main/top10s.csv") %>%
    select(ID, year, bpm, nrgy, dnce, dB, live, val, dur, acous, spch, pop) -> data

head(data)

train <- data[ which(data$year < 2019),]
test <- data[which(data$year >2018),]

head(train)
```

#### Exploratory Data Analysis
```{r plots}
# Beats per Minute Scatterplot and Histogram
plot(train$bpm)
hist(train$bpm)

# Energy Scatterplot and Histogram
plot(train$nrgy)
hist(train$nrgy)

# Danceability Scatterplot and Histogram
plot(train$dnce)
hist(train$dnce)

# Loudness Scatterplot and Histogram
plot(train$dB)
hist(train$dB)

# Liveness Scatterplot and Histogram (untransformed and log transformed)
loglive<-log(train$live)

plot(train$live)
hist(train$live)

hist(loglive)

# Valence Scatterplot and Histogram
plot(train$val)
hist(train$val)

# Duration Scatterplot and Histogram
plot(train$dur)
hist(train$dur)


# Acousticness Scatterplot and Histogram (untransformed and log transformed)
logacous<-log(train$acous)

plot(train$acous)
hist(train$acous)

hist(logacous)


# Speechiness Scatterplot and Histogram (untransformed and log transformed)
logspch<-log(train$spch)

plot(train$spch)
hist(train$spch)

hist(logspch)

# Popularity Scatterplot and Histogram (untransformed and squared transformed)
plot(train$pop)
hist(train$pop)

sqpop<-(train$pop)^2
hist(sqpop)

```

### Analysis/Results

#### Research Question 1: How do songs’ characteristics correlate with their popularity? [Bayesian Linear Regression]

```{r blr-notranform}
# Training Data
lrt <- train[,c("bpm", "nrgy", "dnce", "dB", "live", "val", "dur", "acous", "spch", "pop")]

# Square Transform on the outcome variable in the training set (popularity):
sqtrp<-(lrt$pop)^2
lrt$popsq <- sqtrp

# Test Data
lrtest <- test[,c("bpm", "nrgy", "dnce", "dB", "live", "val", "dur", "acous", "spch", "pop")]

# Square Transform on the outcome variable in the testing set (popularity):
sqtp<-(lrtest$pop)^2
lrtest$popsq <- sqtp
dim(lrtest)
testn<-nrow(lrtest)

# Fitting bayesian linear regression via stan.glm, using gaussian family with identity link to run as linear model -- NO TRANSFORMATION ON THE OUTCOME VARIABLE, 4 Markov chains with 2000 iterations
blrnt<- stan_glm(pop~bpm + nrgy + dnce + dB + live + val + dur + acous + spch , family = gaussian(link = "identity"), data=lrt, algorithm="sampling",seed=551)
blrnt

attributes(blrnt)

# Model Coefficients and Summary
blrnt$coefficients
summary(blrnt, prob=c(.025, .5, .975))

# plotting training outcome to fitted values
plot(lrt$pop, blrnt$fitted.values, ylim=c(55,75))

# prior distribution used for model
prior_summary(blrnt)

# generating test fitted values via model (of note: predict function did not work as expected with this bayesian glm model and predict.glm generated an error)
testfitnt<-blrnt$coefficients[1] + (blrnt$coefficients[2]*lrtest$bpm) + (blrnt$coefficients[3]*lrtest$nrgy) + (blrnt$coefficients[4]*lrtest$dnce) + (blrnt$coefficients[5]*lrtest$dB) + (blrnt$coefficients[6]*lrtest$live) + (blrnt$coefficients[7]*lrtest$val) + (blrnt$coefficients[8]*lrtest$dur) + (blrnt$coefficients[9]*lrtest$acous) + (blrnt$coefficients[10]*lrtest$spch)

testfitnt

# trying predict.glm function instead
#predict.glm(blrnt,lrtest)

# sanity check - same number of predictions as observations in the test set
length(testfitnt)
length(lrtest$pop)

# plotting test set outcome to fitted values
plot(lrtest$pop,testfitnt)

# mean square error
testresidnt<-lrtest$pop-testfitnt
resqnt<-sum(testresidnt^2)
msent<-resqnt/31
msent
```

```{r blr-notranform2}
# Fitting bayesian linear regression via stan.glm, using gaussian family with identity link to run as linear model -- NO TRANSFORMATION ON THE OUTCOME VARIABLE, 4 Markov chains with 2000 iterations
blrnt2<- stan_glm(pop~ nrgy + dB, family = gaussian(link = "identity"), data=lrt, algorithm="sampling",seed=551)
blrnt2


# Model Coefficients and Summary
blrnt2$coefficients
summary(blrnt2, prob=c(.025, .5, .975))

# plotting training outcome to fitted values
plot(lrt$pop, blrnt2$fitted.values, ylim=c(55,75))

# prior distribution used for model
prior_summary(blrnt2)

# generating test fitted values via model (of note: predict function did not work as expected with this bayesian glm model and predict.glm generated an error)
testfitnt2<-blrnt2$coefficients[1] + (blrnt2$coefficients[2]*lrtest$nrgy) + (blrnt2$coefficients[3]*lrtest$dB)

testfitnt2

# trying predict.glm function instead
#predict.glm(blrnt,lrtest)

# sanity check - same number of predictions as observations in the test set
length(testfitnt2)
length(lrtest$pop)

# plotting test set outcome to fitted values
plot(lrtest$pop,testfitnt2)

# mean square error
testresidnt2<-lrtest$pop-testfitnt2
resqnt2<-sum(testresidnt2^2)
msent2<-resqnt2/31
msent2
```

```{r blr-sqtransform, message=FALSE}
# Fitting bayesian linear regression via stan.glm, using gaussian family with identity link to run as linear model -- SQUARE TRANSFORMATION ON THE OUTCOME VARIABLE, 4 Markov chains with 2000 iterations
blr<- stan_glm(popsq~bpm + nrgy + dnce + dB + live + val + dur + acous + spch , family = gaussian(link = "identity"), data=lrt, algorithm="sampling",seed=551)
blr

# Model Coefficients and Summary
blr$coefficients
summary(blr, prob=c(.025, .5, .975))

# plotting training outcome to fitted values
plot(lrt$popsq, blr$fitted.values)

# prior distribution used for model
prior_summary(blr)

# generating test fitted values via model 
testfit<-blr$coefficients[1] + (blr$coefficients[2]*lrtest$bpm) + (blr$coefficients[3]*lrtest$nrgy) + (blr$coefficients[4]*lrtest$dnce) + (blr$coefficients[5]*lrtest$dB) + (blr$coefficients[6]*lrtest$live) + (blr$coefficients[7]*lrtest$val) + (blr$coefficients[8]*lrtest$dur) + (blr$coefficients[9]*lrtest$acous) + (blr$coefficients[10]*lrtest$spch)

testfit

# sanity check - same number of predictions as observations in the test set
length(testfit)
length(lrtest$popsq)

# plotting test set outcome to fitted values
plot(lrtest$popsq,testfit)

# mean square error
testresid<-sqrt(lrtest$popsq)-sqrt(testfit)
resq<-sum(testresid^2)
mse<-resq/31
mse
```

```{r blr-sqtransform-fitting1}
blr2<- stan_glm(popsq~nrgy + dnce + dB + live, family = gaussian(),data=lrt, algorithm="sampling", seed=551)
blr2

# Model Coefficients and Summary
summary(blr2, prob=c(.025, .5, .975))

# plotting training outcome to fitted values
plot(lrt$popsq, blr2$fitted.values)

# generating test fitted values via model 
testfit2<-blr2$coefficients[1] + (blr2$coefficients[2]*lrtest$nrgy) + (blr2$coefficients[3]*lrtest$dnce) + (blr2$coefficients[4]*lrtest$dB) + (blr2$coefficients[5]*lrtest$live)

testfit2

# sanity check - same number of predictions as observations in the test set
length(testfit2)
length(lrtest$popsq)

# plotting test set outcome to fitted values
plot(lrtest$popsq,testfit2)

# mean square error
testresid2<-sqrt(lrtest$popsq)-sqrt(testfit2)
resq2<-sum(testresid2^2)
mse2<-resq2/31
mse2

```

```{r blr-sqtransform-fitting2}
blr3<- stan_glm(popsq~nrgy + dB, family = gaussian(),data=lrt, algorithm="sampling", seed=551)
blr3

# Model Coefficients and Summary
summary(blr3, prob=c(.025, .5, .975))

# plotting training outcome to fitted values
plot(lrt$popsq, blr3$fitted.values)

# generating test fitted values via model 
testfit3<-blr3$coefficients[1] + (blr2$coefficients[2]*lrtest$nrgy) + (blr2$coefficients[3]*lrtest$dB)
testfit3

# sanity check - same number of predictions as observations in the test set
length(testfit3)
length(lrtest$popsq)

# plotting test set outcome to fitted values
plot(lrtest$popsq,testfit3)
plot(sqrt(lrtest$popsq),sqrt(testfit3),xlab="Popularity (Test Set)", ylab="Fitted Value")
abline(lm(sqrt(testfit3) ~ sqrt(lrtest$popsq)))

# mean square error
testresid3<-sqrt(lrtest$popsq)-sqrt(testfit3)
resq3<-sum(testresid3^2)
mse3<-resq3/31
mse3

```

```{r blrplots}
# Distribution of Model 3 coefficients

mcmc_dens(blr3, pars = c("nrgy"))+
  vline_at(-15.3, col="red") + vline_at(-24.5, col="blue") + vline_at(-5.9, col="blue")

mcmc_dens(blr3, pars = c("dB"))+
  vline_at(106.5, col="red") + vline_at(52.9, col="blue") + vline_at(160.5, col="blue")

# Distribution of Model 1 coefficients

mcmc_dens(blr, pars = c("bpm"))+
  vline_at(2.0, col="red")

mcmc_dens(blr, pars = c("nrgy"))+
  vline_at(-20.0, col="red")

mcmc_dens(blr, pars = c("dnce"))+
  vline_at(7.6, col="red")

mcmc_dens(blr, pars = c("dB"))+
  vline_at(99.9, col="red")

mcmc_dens(blr, pars = c("live"))+
  vline_at(-6.9, col="red")

mcmc_dens(blr, pars = c("val"))+
  vline_at(1.1, col="red")

mcmc_dens(blr, pars = c("dur"))+
  vline_at(-2.0, col="red")

mcmc_dens(blr, pars = c("acous"))+
  vline_at(-4.8, col="red")

mcmc_dens(blr, pars = c("spch"))+
  vline_at(0.1, col="red")

```

```{r blrpost}
# Description of Posterior Distibution - Model 3
describe_posterior(blr)
#describe_posterior(blr2)

# Description of Posterior Distibution - Model 5 (Final Selected Model)
describe_posterior(blr3)

# Coefficients/Parameters of model posterior distribution - Model 3
post <- get_parameters(blr)
print(purrr::map_dbl(post,median),digits = 3)

# Coefficients/Parameters of model posterior distribution - Model 5 (Final Selected Model)
post <- get_parameters(blr3)
print(purrr::map_dbl(post,median),digits = 3)

# Highest Density Interval - Model 3
hdi(blr)

# Highest Density Interval - Model 5 (Final Selected Model)
hdi(blr3)

```

#### What are some of the most prevalent characteristics of the top 10 most popular songs in each year?

```{r}
library(tidyverse)
```

### Exploratory Data Analysis

```{r}
songs = read.table("top10s.csv", sep = ",", header = TRUE)[,-1]
head(songs)
```

```{r}
ggplot(songs, aes(year)) + geom_bar() + ggtitle("Number of Songs from Each Year")
```

### Loading Data

```{r}
set.seed(551)
songs = read.table("top10s.csv", sep = ",", header = TRUE)[,-1]
songs = songs %>% group_by(year) %>%
  mutate(rank = row_number()) %>% ungroup() %>%
  mutate(top10 = as.factor(ifelse(rank <= 10, TRUE, FALSE))) %>% ungroup()
songs$top10 = as.factor(songs$top10)
colnames(songs) = c("Title", "Artist", "Genre", "Year", "BeatsPerMinute", "Energy", "Danceability",
                    "Loudness", "Liveness", "Valence", "Duration",
                    "Acousticness", "Speachiness", "Popularity", "Rank", "Top10")
```

```{r}
# splitting into training and test sets
train = songs %>% filter(Year != 2019) %>%
  dplyr::select(-c(Title, Artist, Genre, Year, Rank, Popularity))
test = songs %>% filter(Year == 2019) %>%
  dplyr::select(-c(Title, Artist, Genre, Year, Rank, Popularity))
```

```{r}
# creating distribution plots of each variable
filter(train, Top10 == FALSE)[,-10] %>%
  gather(metric, value) %>% 
  ggplot(aes(value, fill = metric)) + 
  geom_density(show.legend = FALSE) + 
  facet_wrap(~ metric, scales = "free")
```

```{r}
# pairwise correlation plot
library(Hmisc)
library(corrplot)
cor = rcorr(as.matrix(train[,-10]), type = "pearson")
corrplot(cor$r, type = "upper", tl.col = "black", tl.srt = 45)
```

### Naive Bayes Classifier

```{r}
library(naivebayes)
# initial NB fit without undersampling failures
m1 = naive_bayes(top10 ~ ., data = train, usekernel = T) 
```

```{r}
train_pred = predict(m1, train, type = "class")
(train_error = table(train_pred, train$top10))
mean(train_pred != train$top10)

test_pred = predict(m1, test, type = "class")
(test_error = table(test_pred, test$top10))
mean(test_pred != test$top10)

test_error / sum(test_error)
```

### Try Undersampling Unpopular Songs

```{r}
# only include top 40 songs for each year
songs = read.table("top10s.csv", sep = ",", header = TRUE)[,-1]
songs = songs %>% group_by(year) %>%
  mutate(rank = row_number()) %>% ungroup() %>%
  mutate(top10 = ifelse(rank <= 10, TRUE, FALSE)) %>%
  filter(rank <= 40)
  
songs$top10 = as.factor(songs$top10)
train = songs %>% filter(year != 2019) %>%
  dplyr::select(-c(title, artist, top.genre, year, rank, pop))
test = songs %>% filter(year == 2019) %>%
  dplyr::select(-c(title, artist, top.genre, year, rank, pop))
```

```{r}
library(naivebayes)
nb1 = naive_bayes(top10 ~ ., data = train, usekernel = T) 
```

```{r}
# training and test errors for naive bayes with raw predictors
train_pred = predict(nb1, train, type = "class")
(train_error = table(train_pred, train$top10))
mean(train_pred != train$top10)

test_pred = predict(nb1, test, type = "class")
(test_error = table(test_pred, test$top10))
mean(test_pred != test$top10)

test_error / sum(test_error)
```

### Logistic Regression

```{r}
train$top10 = ifelse(train$top10 == TRUE, 1, 0)
lr1 = glm(top10 ~ ., data = train, family = "binomial")
train_pred = predict(lr1, train, type = "response")
```


```{r}
# training and test errors for logistic regression with raw predictors
train_pred = predict(lr1, train, type = "response") > 0.5
(train_error = table(train_pred, train$top10))
mean(train_pred != train$top10)

test_pred = predict(lr1, test, type = "response") > 0.5
(test_error = table(test_pred, test$top10))
mean(test_pred != test$top10)

test_error / sum(test_error)
```

### Centering Values by Year

```{r}
# creating dataframe with centered predictors
songs = read.table("top10s.csv", sep = ",", header = TRUE)[,-1] %>% group_by(year) %>%
  mutate(rank = row_number()) %>% ungroup() %>%
  mutate(top10 = as.factor(ifelse(rank <= 10, TRUE, FALSE))) %>% ungroup()
songs$top10 = as.factor(songs$top10)
centered = songs %>% group_by(year) %>%
  mutate(bpm_ct = bpm - mean(bpm),
         nrgy_ct = nrgy - mean(nrgy),
         dnce_ct = dnce - mean(dnce),
         dB_ct = dB - mean(dB),
         live_ct = live - mean(live),
         val_ct = val - mean(val),
         dur_ct = dur - mean(dur),
         acous_ct = acous - mean(acous),
         spch_ct = spch - mean(spch)) %>% ungroup()
centered = centered[,c(4,16:ncol(centered))]
centered$top10 = as.factor(centered$top10)
colnames(centered) = c("Year", "Top10", "BeatsPerMinute", "Energy", "Danceability",
                    "Loudness", "Liveness", "Valence", "Duration",
                    "Acousticness", "Speachiness")
```

```{r}
train = centered %>% filter(Year != 2019)
test = centered %>% filter(Year == 2019)
```

```{r}
library(naivebayes)
nb2 = naive_bayes(top10 ~ ., data = train, usekernel = T) 
```

```{r}
# training and test errors for naive bayes with centering
train_pred = predict(nb2, train, type = "class")
(train_error = table(train_pred, train$top10))
mean(train_pred != train$top10)

test_pred = predict(nb2, test, type = "class")
(test_error = table(test_pred, test$top10))
mean(test_pred != test$top10)

test_error / sum(test_error)
```

```{r}
# centered distributions
train[,-c(1,2)] %>%
  gather(metric, value) %>% 
  ggplot(aes(value, fill = metric)) + 
  geom_density(show.legend = FALSE) + 
  facet_wrap(~ metric, scales = "free")
```

```{r}
train$top10 = ifelse(train$top10 == TRUE, 1, 0)
lr2 = glm(top10 ~ ., data = train, family = "binomial")
train_pred = predict(lr2, train, type = "response")
```

```{r}
# training and test errors for logistic regression with centering
train_pred = predict(lr2, train, type = "response") > 0.5
(train_error = table(train_pred, train$top10))
mean(train_pred != train$top10)

test_pred = predict(lr2, test, type = "response") > 0.5
(test_error = table(test_pred, test$top10))
mean(test_pred != test$top10)

test_error / sum(test_error)
```

```{r}
summary(lr1)
summary(lr2)
```

```{r}
ggplot(train, aes(spch_ct, dur_ct)) + geom_point(aes(color = as.factor(top10)))
```

```{r}
songs %>% group_by(year) %>%
  summarize(mean(dur))
```

```{r}
songs %>% filter(year == 2011, dur > 224, dur < 242)
```

#### What are the typical duration and beats per minute of the popular songs and how do these patterns change over time?

```{r read-in}
songs = read.csv('top10s.csv')
str(songs)
songs = songs %>% 
  select(-X) %>%
  filter(year <= 2018) %>% rename(genre = top.genre)
metrics = colnames(songs)[5:14]

songs_to_long = function(data = songs){
  # Wrapper function
  # Pivot to long format on metrics vars only (numeric, excluding year)
  pivot_longer(data, cols=5:14,
               names_to='metric', values_to='value')
}
songs_long = songs_to_long()
str(songs_long)
```

```{r plotting-scales}
# Reusable scales for ggplot
year_scale_discrete = scale_x_discrete('Year',
                                       breaks=as.factor(seq(2010, 2018, 2)),
                                       label=seq(2010, 2018, 2))
year_scale_continuous = scale_x_discrete('Year',
                                         breaks=seq(2010, 2018, 2),
                                         label=seq(2010, 2018, 2))
```

```{r smooth-all}
# KDEs for all numerical variables (faceted)
ggplot(songs_long) +
  geom_smooth(aes(year, value)) +
  facet_wrap(vars(metric))
```

```{r, fig.width=6, fig.height=18}
# Boxplot of all numerical variables by year
ggplot(songs_long) +
  geom_boxplot(aes(group=year,
                      y = value, x=year)) +
  facet_grid(rows=vars(metric), scales='free_y') +
  scale_x_continuous('Year',
                     breaks = 2010:2018,
                     labels = 2010:2018,
                     sec.axis = dup_axis())
```

There definitely seem to be some zero values that need to be excluded, although some of these may actually be valid.

```{r clean-songs-1}
# We will remove this one observation, since all the values seem invalid
songs %>% filter(dB<=-40)
songs = songs %>% filter(title != 'Million Years Ago')
songs_long = songs_to_long(songs)
```

```{r, fig.width=6, fig.height=18}
ggplot(songs_long) +
  geom_boxplot(aes(group=year,
                      y = value, x=year)) +
  facet_grid(rows=vars(metric), scales='free_y') +
  scale_x_continuous('Year',
                     breaks = 2010:2018,
                     labels = 2010:2018,
                     sec.axis = dup_axis())
```

There are still several zero values for `pop` although these might be valid.

```{r clean-songs-2}
songs %>% filter(pop<=0.1)
# Leave these in for now I guess
```

```{r smooth-dur-bpm}
# KDEs for bpm and duration only
ggplot(songs_long %>% filter(metric %in% c('bpm', 'dur'))) +
  geom_smooth(aes(year, value)) +
  facet_grid(rows=vars(metric), scales='free_y') +
  theme(aspect.ratio=0.6)
```

`val`, `bpm`, `dur`, `dB`, `dnce`, and `nrgy` seem relevant to our interests.

```{r boxplot-hype, fig.width=6, fig.height=8}
plot.vars = sort(c('val', 'bpm', 'dur', 'dB', 'dnce', 'nrgy'))

p = ggplot(songs_long %>%
         filter(metric %in% plot.vars)) +
  geom_boxplot(aes(group=year,
                      y = value, x=year)) +
  facet_wrap(vars(as.factor(metric)), scales='free_y') +
  scale_x_continuous('Year',
                     breaks = 2010:2018,
                     labels = 2010:2018,
                     sec.axis = dup_axis())

p + geom_segment(data = ggplot_build(p)$data[[1]] %>%
                   mutate(metric = factor(PANEL, labels=plot.vars)),
                 aes(x=xmin, xend=xmax, y=middle, yend=middle),
                 colour="red", size=1.5) +
  facet_wrap(vars(as.factor(metric)),
             scales='free_y',
             ncol=2)

ggplot_build(p)$data[[1]] %>% str
with(ggplot_build(p)$data[[1]], factor(PANEL, labels=plot.vars))
```

Duration and dB don't seem particularly interesting, so we'll focus on the remaining four plotted above.

```{r}
plot.vars = sort(c('val', 'bpm', 'dnce', 'nrgy'))
```


```{r hype-KDE, fig.width=6, fig.height=8}
ggplot(songs_long %>%
         filter(metric %in% c('bpm', 'dur', 'dB', 'dnce', 'nrgy', 'val'))) +
  geom_smooth(aes(y = value, x=year)) +
  facet_grid(rows=vars(metric), scales='free_y') +
  scale_x_continuous('Year',
                     breaks = 2010:2018,
                     labels = 2010:2018,
                     sec.axis = dup_axis())
```

```{r, eval=FALSE}
unique(songs$genre)

# Rock and "indie" are classed as pop
# Rap is classed as hip hop
# Hollywood, contemporary country, and Irish singer-songwriter
#   are classed as other
songs = songs %>%
  mutate(genre_cat =
           map_chr(genre,
                   ~switch(.,
                           "neo mellow" = 'soul rnb',
                           "detroit hip hop" = 'hip hop',          
                           "dance pop" = 'pop',
                           "pop" = 'pop',                      
                           "canadian pop" = 'pop',
                           "hip pop" = 'hip hop',                  
                           "barbadian pop" = 'pop',
                           "atl hip hop" = 'hip hop',              
                           "australian pop" = 'pop',
                           "indie pop" = 'pop',                
                           "art pop" = 'pop',
                           "colombian pop" = 'pop',            
                           "big room" = 'electronica',
                           "british soul" = 'soul rnb',             
                           "chicago rap" = 'hip hop',
                           "acoustic pop" = 'pop',             
                           "permanent wave" = 'electronica',
                           "boy band" = 'pop',                 
                           "baroque pop" = 'pop',
                           "celtic rock" = 'pop',              
                           "electro" = 'electronica',
                           "complextro" = 'electronica',               
                           "canadian hip hop" = 'hip hop',
                           "candy pop" = 'pop',                
                           "alaska indie" = 'pop',
                           "folk-pop" = 'pop',                 
                           "metropopolis" = 'pop',
                           "house" = 'electronica',                    
                           "australian hip hop" = 'hip hop',
                           "electropop" = 'pop',               
                           "australian dance" = 'electronica',
                           "hollywood" = 'other',                
                           "canadian contemporary r&b" = 'soul rnb',
                           "irish singer-songwriter" = 'other',  
                           "tropical house" = 'electronica',
                           "belgian edm" = 'electronica',              
                           "french indie pop" = 'pop',
                           "hip hop" = 'hip hop',                  
                           "danish pop" = 'pop',
                           "latin" = 'latin',                    
                           "canadian latin" = 'latin',
                           "electronic trap" = 'electronica',          
                           "edm" = 'electronica',
                           "electro house" = 'electronica',            
                           "downtempo" = 'electronica',
                           "brostep" = 'electronica',                  
                           "contemporary country" = 'other',
                           "moroccan pop" = 'pop')),
         .after = genre)
```

Problem: way too many in the pop category, as I should have expected

```{r}
# songs %>% group_by(genre_cat) %>% count
```


```{r K-means}
# Get the median values for all metrics on each genre
genre_medians = songs %>%
  group_by(genre) %>%
  summarize(across(all_of(metrics), median)) %>%
  column_to_rownames(var='genre')

genre_kmeans = kmeans(genre_medians, 4)
fitted(genre_kmeans, 'classes') %>% sort

fviz_nbclust(genre_medians, kmeans, method='wss')
fviz_cluster(genre_kmeans, data = genre_medians, repel=TRUE)
```

```{r}
save(songs, year_scale_continuous, year_scale_discrete,
     metrics, plot.vars, songs_to_long,
     file = 'EDA-data.Rdata')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(aTSA)
load('EDA-data.Rdata')
```

```{r}
(loaded_data = names(as.list(.GlobalEnv)))
```

It seems like it could be interesting to investigate bpm first.

```{r}
# We'll randomly sample 35 observations from each year to simplify computation for the acf
songs %>% count(year)
songs_short = songs %>%
  group_by(year) %>% slice_sample(n = 35) %>% ungroup %>%
  arrange(year)
```


```{r}
# Check ACF for bpm
acf(songs %>% group_by(year) %>%
      summarize(mean_bpm = mean(bpm)) %>% select(mean_bpm),
    frequency=35)

# For nrgy
acf(songs %>% group_by(year) %>%
      summarize(mean_nrgy = mean(nrgy)) %>% select(mean_nrgy))

# For dnce
acf(songs %>% group_by(year) %>%
      summarize(mean_dnce = mean(dnce)) %>% select(mean_dnce))

# For valence
acf(songs %>% group_by(year) %>%
      summarize(mean_val = mean(val)) %>% select(mean_val))
```

The ACF plots for bpm and energy have a fairly similar pattern, although there aren't significant autocorrelations for the year-dependent means of either variable in this very underpowered assessment.

Looking back at the scatterplots, it appears that the covariance structure between dnce, nrgy, and val can be exploited in construtructing a hierarchical model 

```{r}
# Check scatterplots again with just these four variables
plot(songs %>% select(plot.vars))
```

### Testing out greta

```{r}
library(greta)
```

```{r}
ones(3,3)
?greta::operators
library(bayesplot)
```

### Time series

```{r data-setup}
metrics4 = c('bpm', 'dnce', 'nrgy', 'val')

# yr is variable for shifted year
songs = songs %>% mutate(yr = year-2010)

# Means by year
means = songs %>%
  group_by(yr) %>%
  summarize(across(metrics, mean))
# sd2010 = songs %>% filter(yr==2010) %>%
#   summarize(across(all_of(metrics), sd))

# means_long = left_join(songs, means, by='yr', suffix=c('', '_mean')) %>%
#     select(ends_with('_mean')) %>% rename_with(~gsub('_mean', '', .))
# sd2010_long = left_join(songs, sd2010, by='yr', suffix=c('', '_sd2010')) %>%
#   select(ends_with('_sd2010'))
# lagged_means = means %>% summarize(across(yr),
#                                    across(-yr,
#                                   ~c(NA, .)[row_number()],
#                                   .names= '{.col}_lag1'))

# Subtract off mean for 2010, divide by standard deviation across all years
songs_std = songs %>%
  mutate(across(metrics, ~(.-means[[1, cur_column()]]) / sd(.)))
# Compute means of standardized metrics by year
means_std = songs_std %>% group_by(yr) %>% summarize(across(metrics, mean))
```

Prior formulation:
\begin{align*}
\mu &\sim N(0, 2)\\
\beta_{yr} &\sim N(0,1)
\end{align*}

We standardize the observed metrics, so we can use the correlation matrix for 2018 as a point estimate for the overall covariance matrix. This lets us use data we otherwise would not be able to use effectively in the model fitting, since the covariates are lagged.

```{r time-series-1}
# Trim down to only the four metrics for now
met = metrics4

# Matrix of individual song observations
M = cbind(int = 1, select(songs_std, yr, met))
p = ncol(M)
# Matrix without year or intercept
M_met = select(songs_std, met)
M_met18 = M_met[M$yr==8,] # 2018 only

# Design matrix (by-year means)
X = cbind(int = 1, means_std) %>% select(yr, met)
# Matrix of differences
D = as_data(X[-1,-1] - X[-9,-1])

df_Sigma = 30  # Degrees of freedom for esimating covariance from 2018
# Prior estimate for the covariance matrix 
Lambda0 = solve( cov(M_met) )
Lambda_met = wishart(df_Sigma, (1/df_Sigma) * Lambda0)
Lambda_err = wishart(df_Sigma, (2/df_Sigma) * Lambda0)
# Sigma0[3:p, 3:p] = cor(X_metrics_8)
# Sigma0[3:p, 2] <- Sigma0[2, 3:p] <- 0

beta_yr = normal(0,1)
beta_met = 2*beta(3, 2, dim=3) - 1

hist(songs_std %>% filter(yr==0) %>% pull(bpm))
ggplot(data = songs_std, aes(x = bpm, y = dnce)) +
  geom_point() +
  geom_point(data = means_std, color='red')

songs %>% count(year) %>% summarize(mean(n))
```



```{r}
# beta.param = c(3,2)
# d = data.frame(x = seq(-1, 1, by=0.01)) %>%
#   mutate(y = dbeta((x+1)/2, beta.param[1], beta.param[2]))
# ggplot(d, aes(x,y)) + geom_line()
#   qbeta(.5,3,2)*2-1
```

```{r}
# b = matrix(rnorm(160), ncol=4)
# s = cbind(c(1,rep(0,4)), rbind(0, t(b)%*%b))
# sqrt(s)
# solve(s)
```


### Heirarchical Bayes

Will not use an trend term for year.

```{r hierarchical-setup}
# Re-make songs dataframe including 2018
# Years will be expressed as years since 2010, one-indexed
Songs = read.csv('top10s.csv')
Songs = Songs %>% select(-X) %>% mutate(year = year-2009)

n = nrow(Songs)
k = length(unique(Songs$year))

X.df = Songs %>% select(year, metrics4)
X = X.df %>% select(-year) %>% as_data
Xbar = X.df %>% summarize(across(metrics4, mean))
Xbar_i = X.df %>% group_by(year) %>%
  summarize(across(metrics4, mean)) %>% select(-year) %>% as_data

m_Sigma = 50
Psi0 = solve((1/n)*t(X)%*%X)
# Psi = solve(var(X)) %>% as_data
# distribution(Psi) = wishart(1, Psi0)
Psi = wishart(1, Psi0)
Sigma = solve(Psi)

Psi_i0 = map(unique(Songs$year),
            ~((1/sum(Songs$year==.x))*
                t(X[Songs$year==.x,])%*%X[Songs$year==.x,] %>% solve))
Psi_i = map(unique(Songs$year),
            ~wishart(m_Sigma, m_Sigma*Psi))

Theta = multivariate_normal(zeros(10,4), solve(Psi),
                            dim=4, n_realisations=k) # k x 4

# mu = Xbar %>% as_data
# distribution(mu) = multivariate_normal(Xbar, (1/n)*solve(Psi), dim=4)
mu = multivariate_normal(t(colMeans(X)), (1/n)*solve(Psi), dim=4)

epsilon = zeros(n, 4)

Theta_effect = model.matrix(~as.factor(year), Songs)%*%Theta

EX = ones(n)%*%mu + Theta_effect
distribution(X) = multivariate_normal(EX, Psi, dim=4, n_realisations=n)
```

```{r}
model1 = model(mu, Theta, Psi)
model2 = model(mu)
```

```{r eval=FALSE}
# Need to fix tensorflow bug
init = replicate(4, initials(mu = as_data(Xbar+rnorm(4, 0, 3))), simplify=FALSE)
sim1 = mcmc(model2, n_samples = 100, warmup=100, initial_values=init)
```
